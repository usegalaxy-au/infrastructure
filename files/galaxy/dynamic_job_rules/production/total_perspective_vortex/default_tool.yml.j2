global:
  default_inherits: default

tools:
  default:
    cores: 1
    mem: cores * 3.8
    env: 
      HDF5_USE_FILE_LOCKING: "FALSE"
    context:
      partition: main
      test_cores: 1  # TODO: test_mem?
      max_concurrent_job_count_for_tool_total: null
      max_concurrent_job_count_for_tool_user: null

      # pulsar score
      pulsar_score: null  # scores set in tool_pulsar_scores.yml. Not every tool will have a score
      pulsar_score_pulsar_threshold: 10  # above this score, prefer to send jobs to pulsar
      pulsar_score_slurm_threshold: 0.3  # below this score, prefer to send jobs to slurm
      pulsar_score_slurm_max_cores: 12  # if cores >= this number, do not set preference for slurm
      pulsar_score_slurm_max_mem: 48  # if mem >= this number, do not set preference for slurm
 
      # singularity and docker volumes
      slurm_singularity_volumes: "{{ slurm_singularity_volumes }}"
      slurm_docker_volumes: "{{ slurm_docker_volumes }}"
      pulsar_singularity_volumes: "{{ pulsar_singularity_volumes }}"
      pulsar_docker_volumes: "{{ pulsar_docker_volumes }}"
    scheduling:
      reject:
        - offline
    rules:
    - id: max_concurrent_job_count_for_tool_rule
      if: |
        total_limit_exceeded = False
        user_limit_exceeded = False
        if max_concurrent_job_count_for_tool_total:
          total_limit_exceeded = helpers.concurrent_job_count_for_tool(app, tool) >= max_concurrent_job_count_for_tool_total
        if max_concurrent_job_count_for_tool_user and not total_limit_exceeded:
          user_limit_exceeded = helpers.concurrent_job_count_for_tool(app, tool, user) >= max_concurrent_job_count_for_tool_user
        total_limit_exceeded or user_limit_exceeded
      execute: |
        from galaxy.jobs.mapper import JobNotReadyException
        raise JobNotReadyException()
    - id: pulsar_score_prefer_pulsar_rule
      if: |
        result = pulsar_score is not None and (
          helpers.tag_values_match(entity, ['pulsar'], [])  # tool is eligible to run on pulsar
          and pulsar_score > pulsar_score_pulsar_threshold  # tool scores highly for resources used * runtime per GB of input/output data
        )
        if result:
          log.info(f"++ ---tpv rank debug::: preferring pulsar for tool {tool.id} (pulsar score {pulsar_score})")
        result
      scheduling:
        prefer:
          - pulsar
    - id: pulsar_score_prefer_slurm_rule
      if: |
        from numbers import Number
        result = pulsar_score is not None and isinstance(entity.mem, Number) and (
          helpers.tag_values_match(entity, ['pulsar'], [])  # tool is eligible to run on pulsar
          and pulsar_score < pulsar_score_slurm_threshold  # tool has a low score for resources used * runtime per GB of input/output data
          and entity.cores < pulsar_score_slurm_max_cores  # job resource requirements are not so high as to make automatic slurm assignment difficult 
          and entity.mem < pulsar_score_slurm_max_mem
        )
        if result:
          log.info(f"++ ---tpv rank debug::: preferring slurm for tool {tool.id} (pulsar score {pulsar_score})")
        result
      scheduling:
        prefer:
          - slurm
    rank: |
      if len(candidate_destinations) <= 1:
        log.info("++ ---tpv rank debug: 1 or fewer destinations: returning candidate_destinations")
        final_destinations = candidate_destinations
      else:
        log.info(f"++ ---tpv rank debug: ranking destinations for job with tool {tool.id}, cores: {cores}, mem: {mem}")
        import random
        from sqlalchemy import text
        from tpv.core.entities import TagType

        raw_sql_query = """
            select destination_id, state, count(id), sum(cores), sum(mem)
            from (
                select id,
                      CAST((REGEXP_MATCHES(encode(destination_params, 'escape'),'ntasks=(\d+)'))[1] as INTEGER)  as cores,
                      CAST((REGEXP_MATCHES(encode(destination_params, 'escape'),'mem=(\d+)'))[1] as INTEGER)  as mem,
                      state,
                      destination_id
                from job
                where state='queued' or state='running'
                order by destination_id
            ) as foo
            group by destination_id, state;
        """

        try:
          results = app.model.context.execute(text(raw_sql_query))
          db_queue_info = {}
          for row in results:
              # log.info(f"++ ---tpv rank debug: row returned by db query: {str(row)}")
              destination_id, state, count_id, sum_cores, sum_mem = row
              if not destination_id in db_queue_info:
                  db_queue_info[destination_id] = {
                    'queued': {'sum_cores': 0, 'sum_mem': 0.0, 'job_count': 0},
                    'running': {'sum_cores': 0, 'sum_mem': 0.0, 'job_count': 0},
                  }
              db_queue_info[destination_id][state] = {'sum_cores': sum_cores, 'sum_mem': sum_mem, 'job_count': count_id}

          def score_preferred(dest, ent):
              """
              Computes a compatibility score between tag sets based only on a 'prefer' tag in one matching a positive tag in the other.
              :param ent:
              :return:
              """
              def a_prefers_b(a_tags, b_tags):
                  return any(
                    tag for tag in a_tags.filter(tag_type = TagType.PREFER)
                    if list(b_tags.filter(tag_type = [TagType.ACCEPT, TagType.PREFER, TagType.REQUIRE], tag_value = tag.value))
                  )
              dest_tags = dest.tpv_dest_tags
              ent_tags = ent.tpv_tags
              score = 1 if a_prefers_b(dest_tags, ent_tags) or a_prefers_b(ent_tags, dest_tags) else 0
              return score

          def destination_usage_proportion(destination):
            if not destination.context.get('destination_total_mem') or not destination.context.get('destination_total_cores'):
              raise Exception(f"++ ---tpv rank debug: At least one of destination_total_mem, destination_total_cores is unavailable")
            destination_total_cores = destination.context.get('destination_total_cores')
            return_value = sum([db_queue_info.get(destination.id, {}).get(state, {}).get('sum_cores', 0) for state in ['queued', 'running']])/destination_total_cores
            log.info(f"++ ---tpv rank debug: returning usage proportion value for destination {destination.id}: {str(return_value)}")
            return return_value

          def destination_availability_score(destination):
              if not destination.context.get('destination_total_mem') or not destination.context.get('destination_total_cores'):
                raise Exception(f"++ ---tpv rank debug: At least one of destination_total_mem, destination_total_cores is unavailable")
              destination_cores_committed = sum([db_queue_info.get(destination.id, {}).get(state, {}).get('sum_cores', 0) for state in ['queued', 'running']])
              destination_mem_committed = sum([db_queue_info.get(destination.id, {}).get(state, {}).get('sum_mem', 0) for state in ['queued', 'running']])
              available_cores = destination.context['destination_total_cores'] - destination_cores_committed
              available_mem = float(destination.context['destination_total_mem']) - (float(destination_mem_committed)/1024)
 
              the_score = min(available_cores/cores, available_mem/mem) # returns the number of jobs with cores/mem that could run at destination
              log.info(f"++ ---tpv rank debug: The availablity score for destination {destination.id} is {the_score}")
              return the_score

          # # Previous ranking method
          # Sort by cpu usage as with previous method. This time queued cpu commitment counts towards CPU usage
          # candidate_destinations.sort(key=lambda d: (destination_usage_proportion(d), random.randint(0,9)))

          # New ranking method: consider memory use at destination as well as CPU use
          # Sort destinations by the number of jobs with these values of entity cores/mem that would be able to run there
          candidate_destinations.sort(key=lambda d: (-1 * score_preferred(d, entity), -1 * destination_availability_score(d), random.randint(0,9)))

          final_destinations = candidate_destinations
          log.info(f"++ ---tpv rank debug: destinations ranked: {[d.id for d in final_destinations]}")
        except Exception:
          log.exception("++ ---tpv rank debug: An error occurred with database query and/or surrounding logic. Using a weighted random candidate destination")
          final_destinations = helpers.weighted_random_sampling(candidate_destinations)
      final_destinations
