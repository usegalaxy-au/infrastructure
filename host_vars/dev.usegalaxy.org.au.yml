# Specific settings for galaxy dev application/web server

# Login override - checksum for Login.vue
galaxy_login_checksum_expected: fd733fa7ea21a22f6f99a095f8c2646b

# total perspective vortex package
tpv_commit_id: "b32e909f68c756f3075d33303db1fb010d21a0a1"
total_perspective_vortex_package: "git+https://github.com/usegalaxy-au/total-perspective-vortex@{{ tpv_commit_id }}"

# variables for attaching mounted volume to application server
attached_volumes:
  - device: /dev/vdb
    path: /mnt
    fstype: ext4

certbot_domains:
  - "{{ hostname }}"
  - "*.interactivetoolentrypoint.interactivetool.{{ hostname }}"
certbot_dns_provider: cloudflare
certbot_dns_credentials:
  api_token: "{{ vault_dns_cloudflare_api_token }}"
dns-cloudflare-propagation-seconds: 60

nginx_ssl_servers:
  - galaxy
  - galaxy-gie-proxy

#gie proxy hostname
interactive_tools_server_name: "{{ hostname }}"

galaxy_db_user_password: "{{ vault_dev_db_user_password }}"

# ansible-galaxy
galaxy_dynamic_job_rules_src_dir: files/galaxy/dynamic_job_rules/dev
galaxy_dynamic_job_rules_dir: "{{ galaxy_root }}/dynamic_job_rules"
galaxy_dynamic_job_rules:
  - dynamic_rules/destination_mapper.py
  - dynamic_rules/tool_destinations.yml
  - readme.txt

galaxy_tools_indices_dir: "{{ galaxy_root }}"
galaxy_tmp_dir: "{{ galaxy_root }}/tmp"

galaxy_repo: https://github.com/galaxyproject/galaxy.git
galaxy_commit_id: release_21.09

# Do not use extra tool_conf file for cloudstor tool
use_cloudstor_conf: false

galaxy_file_path: "{{ galaxy_root }}/data"
nginx_upload_store_base_dir: "{{ galaxy_file_path }}/upload_store"
nginx_upload_store_dir: "{{ nginx_upload_store_base_dir }}/uploads"
nginx_upload_job_files_store_dir: "{{ nginx_upload_store_base_dir }}/job_files"

# ITs tool conf overrides.
tool_config_files: "{{ cloudstor_settings['tool_config_files'] if use_cloudstor_conf|d(false) == true else default_settings['tool_config_files'] }},{{ galaxy_config_dir }}/tool_conf_interactive.xml"

host_galaxy_config_templates:
  - src: "{{ galaxy_config_template_src_dir }}/config/oidc_backends_config.xml.j2"
    dest: "{{ galaxy_config_dir}}/oidc_backends_config.xml"
  - src: "{{ galaxy_config_template_src_dir }}/config/dev_job_conf.yml.j2"
    dest: "{{ galaxy_config_dir}}/job_conf.yml"

host_galaxy_config_files:
  - src: "{{ galaxy_config_file_src_dir }}/config/oidc_config.xml"
    dest: "{{ galaxy_config_dir}}/oidc_config.xml"
  - src: files/galaxy/dynamic_job_rules/dev/total_perspective_vortex/vortex_config.yml
    dest: "{{ galaxy_config_dir}}/vortex_rules_local.yml"
  - src: "{{ galaxy_config_file_src_dir }}/config/local_tool_conf_dev.xml"
    dest: "{{ galaxy_config_dir }}/local_tool_conf.xml"

host_galaxy_config:  # renamed from __galaxy_config
  galaxy:
    admin_users: "{{ machine_users | selectattr('email', 'defined') | map(attribute='email') | join(',') }}" # everyone is an admin on dev
    brand: "Australia Dev"
    database_connection: "postgresql://galaxy:{{ vault_dev_db_user_password }}@dev-db.usegalaxy.org.au:5432/galaxy"
    id_secret: "{{ vault_dev_id_secret }}"
    file_path: "{{ galaxy_file_path }}"
    galaxy_infrastructure_url: 'https://dev.usegalaxy.org.au'
    enable_oidc: true
    oidc_config_file: "{{ galaxy_config_dir }}/oidc_config.xml"
    oidc_backends_config_file: "{{ galaxy_config_dir }}/oidc_backends_config.xml"
    nginx_upload_store: "{{ nginx_upload_store_dir }}"
    nginx_upload_path: '/_upload'
    nginx_upload_job_files_store: "{{ nginx_upload_job_files_store_dir }}"
    nginx_upload_job_files_path: '/_job_files'
    interactivetools_enable: true
    interactivetools_map: "{{ gie_proxy_sessions_path }}"
    cleanup_job: never
    job_config_file: "{{ galaxy_config_dir }}/job_conf.yml"
    show_welcome_with_login: false
    enable_mulled_containers: true
    enable_beta_containers_interface: true
    watch_job_rules: true  # important for total perspective vortex
    dependency_resolvers:
      - type: tool_shed_packages
      - type: galaxy_packages
      - type: conda
      - type: galaxy_packages
        versionless: true
      - type: conda
        versionless: true

galaxy_handler_count: 2   ############# europe uses 5, this could be host specific

# NFS stuff
nfs_exports:
    - "{{ galaxy_root }}  *(rw,async,no_root_squash,no_subtree_check)"

#Galaxy Job Conf  # this is no longer used but should stay as an example while job confs are updated to yaml
galaxy_jobconf:
    plugin_workers: 4
    handlers:
        count: "{{ galaxy_handler_count }}"
    plugins:
      - id: dynamic
        params:
          rules_module: dynamic_rules
      - id: local
        load: galaxy.jobs.runners.local:LocalJobRunner
        workers: 4
      - id: slurm
        load: galaxy.jobs.runners.slurm:SlurmJobRunner
      - id: pulsar_embedded
        load: galaxy.jobs.runners.pulsar:PulsarEmbeddedJobRunner
        params:
            pulsar_config: "{{ galaxy_config_dir }}/pulsar_app.yml"
      - id: pulsar_au_01
        load: galaxy.jobs.runners.pulsar:PulsarMQJobRunner
        params:
            amqp_url: "pyamqp://galaxy_au:{{ vault_rabbitmq_password_galaxy_au_dev }}@dev-queue.usegalaxy.org.au:5671//pulsar/galaxy_au?ssl=1"
            galaxy_url: "https://dev.usegalaxy.org.au"
            manager: _default_
            amqp_acknowledge: True
            amqp_ack_republish_time: 300
            amqp_consumer_timeout: 2.0
            amqp_publish_retry: True
            amqp_publish_retry_max_retries: 60
      - id: pulsar_nci_test_runner
        load: galaxy.jobs.runners.pulsar:PulsarMQJobRunner
        params:
            amqp_url: "pyamqp://galaxy_nci_test:{{ vault_rabbitmq_password_galaxy_nci_test }}@dev-queue.usegalaxy.org.au:5671//pulsar/galaxy_nci_test?ssl=1"
            galaxy_url: "https://dev.usegalaxy.org.au"
            manager: _default_
            amqp_acknowledge: True
            amqp_ack_republish_time: 1200
            amqp_consumer_timeout: 2.0
            amqp_publish_retry: True
            amqp_publish_retry_max_retries: 60
      - id: pulsar_eu_gpu
        load: galaxy.jobs.runners.pulsar:PulsarMQJobRunner
        params:
            amqp_url: "pyamqp://galaxy_eu_gpu:{{ vault_rabbitmq_password_galaxy_eu_gpu }}@dev-queue.usegalaxy.org.au:5671//pulsar/galaxy_eu_gpu?ssl=1"
            galaxy_url: "https://dev.usegalaxy.org.au"
            manager: _default_
            amqp_acknowledge: True
            amqp_ack_republish_time: 1200
            amqp_consumer_timeout: 2.0
            amqp_publish_retry: True
            amqp_publish_retry_max_retries: 60
    default_destination: gateway
    destinations:
      - id: local
        runner: local
      - id: gateway
        runner: dynamic
        params:
            type: python
            function: gateway
      - id: dynamic_dtd
        runner: dynamic
        params:
          type: dtd
      - id: slurm_1slot
        runner: slurm
        params:
            nativeSpecification: "--nodes=1 --ntasks=1 --ntasks-per-node=1 --mem=3880"
      - id: slurm_2slots
        runner: slurm
        params:
            nativeSpecification: "--nodes=1 --ntasks=2 --ntasks-per-node=2 --mem=7760"
      - id: pulsar_destination
        runner: pulsar_au_01
        params:
              jobs_directory: /mnt/pulsar/files/staging
              transport: curl
              remote_metadata: "false"
              default_file_action: remote_transfer
              dependency_resolution: remote
              rewrite_parameters: "true"
              persistence_directory: /mnt/pulsar/files/persisted_data
              submit_native_specification: "--nodes=1 --ntasks=2 --ntasks-per-node=2 --mem=7495"
      - id: pulsar-nci-test_small
        runner: pulsar_nci_test_runner
        params:
              jobs_directory: /mnt/pulsar/files/staging
              transport: curl
              remote_metadata: "false"
              default_file_action: remote_transfer
              dependency_resolution: remote
              rewrite_parameters: "true"
              persistence_directory: /mnt/pulsar/files/persisted_data
              submit_native_specification: "--nodes=1 --ntasks=2 --ntasks-per-node=2 --mem=6168"
      - id: pulsar-nci-test_mid
        runner: pulsar_nci_test_runner
        params:
              jobs_directory: /mnt/pulsar/files/staging
              transport: curl
              remote_metadata: "false"
              default_file_action: remote_transfer
              dependency_resolution: remote
              rewrite_parameters: "true"
              persistence_directory: /mnt/pulsar/files/persisted_data
              submit_native_specification: "--nodes=1 --ntasks=8 --ntasks-per-node=8 --mem=24675"
      - id: pulsar-nci-test_big
        runner: pulsar_nci_test_runner
        params:
              jobs_directory: /mnt/pulsar/files/staging
              transport: curl
              remote_metadata: "false"
              default_file_action: remote_transfer
              dependency_resolution: remote
              rewrite_parameters: "true"
              persistence_directory: /mnt/pulsar/files/persisted_data
              submit_native_specification: "--nodes=1 --ntasks=16 --ntasks-per-node=16 --mem=49350"
      - id: pulsar-eu-gpu-test
        runner: pulsar_eu_gpu
        params:
              jobs_directory: /mnt/shared/files/staging
              transport: curl
              remote_metadata: "false"
              default_file_action: remote_transfer
              dependency_resolution: remote
              rewrite_parameters: "true"
              persistence_directory: /mnt/shared/files/persisted_data
              submit_native_specification: "--nodes=1 --ntasks=40 --ntasks-per-node=40 --mem=110000"
      - id: interactive_local
        runner: local
        params:
              docker_enabled: true
              docker_volumes: $defaults
              docker_sudo: false
              docker_net: bridge
              docker_auto_rm: true
              docker_set_user: ''
              docker_require_container: true
      - id: interactive_pulsar
        runner: pulsar_embedded
        params:
              docker_enabled: true
              docker_volumes: $defaults
              docker_sudo: false
              docker_net: bridge
              docker_auto_rm: true
              docker_set_user: ''
              docker_require_container: true
              container_monitor_result: callback
    tools:
      - id: interactive_tool_ethercalc
        destination: interactive_local
      - id: interactive_tool_rstudio
        destination: interactive_local
      - id: interactive_tool_jupyter_notebook
        destination: interactive_pulsar
      - id: interactive_tool_phinch
        destination: interactive_local
    limits:
      #General limits for user submission
      - type: anonymous_user_concurrent_jobs
        value: 1
      - type: registered_user_concurrent_jobs
        value: 10

# cvmfs
cvmfs_cache_base: /mnt/var/lib/cvmfs

# vars for setting up .pgpass
pg_db_password:
  galaxy: "{{ vault_dev_db_user_password }}"
  reader: "{{ vault_dev_db_reader_password }}"
  tiaasadmin: "{{ vault_dev_db_tiaasadmin_password }}"
db_address: "dev-db.usegalaxy.org.au"
gxadmin_ubuntu_config_dir: /home/ubuntu/.config

# TIaaS specific settings
tiaas_galaxy_db_host: "dev-db.usegalaxy.org.au"
tiaas_galaxy_db_port: "5432"
tiaas_galaxy_db_user: "tiaas"
tiaas_galaxy_db_pass: "{{ tiaas_galaxy_db_password }}"
tiaas_info:
  owner: "Galaxy Australia Dev"
  owner_email: help@genome.edu.au
  owner_site: "https://dev.usegalaxy.org.au"
  domain: "dev.usegalaxy.org.au"

  # Create a cron job to disassociate training roles from groups after trainings have expired, set to `false` to disable
tiaas_disassociate_training_roles:
  hour: 9      # optional, defaults to 0
  minute: 0    # optional, defaults to 0

# AAF specific settings
aaf_issuer_url: "{{ vault_aaf_issuer_url_dev }}"
aaf_client_id: "{{ vault_aaf_client_id_dev }}"
aaf_client_secret: "{{ vault_aaf_client_secret_dev }}"

# remote-pulsar-cron variables
rpc_skip_cron_setup: false
rpc_db_connection_string: "postgres://reader:{{ vault_dev_db_reader_password }}@dev-db.usegalaxy.org.au:5432/galaxy"

rpc_pulsar_machines:
  - pulsar_name: dev-pulsar
    pulsar_ip_address: "{{ hostvars['dev-pulsar']['ansible_ssh_host'] }}"
    ssh_key: /home/ubuntu/.ssh/ubuntu_maintenance_key
    delete_jwds: true
    keep_error_days: 7
    cron_hour: "07"
    cron_minute: "32"

extra_keys:
  - id: ubuntu_maintenance_key
    type: private
