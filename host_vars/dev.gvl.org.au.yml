# Specific settings for galaxy dev application/web server

add_hosts_handlers: yes

common_logrotate_manage_rsyslog: true

# total perspective vortex
# tpv_version: "2.2.4"
# tpv_repo: https://github.com/usegalaxy-au/total-perspective-vortex
# tpv_commit_id: d8e336b1cc889237c155d0ad318051c36e5636e6

# variables for attaching mounted volume to application server
attached_volumes:
  - device: /dev/vdb
    path: /mnt
    fstype: ext4

shared_mounts:
  - path: /mnt/test_mount
    src: 115.146.87.37:/galaxy-backup-au
    fstype: nfs
    state: mounted

certbot_domains:
  - "{{ hostname }}"
  - "*.interactivetoolentrypoint.interactivetool.{{ hostname }}"
  - "*.ep.interactivetool.{{ hostname }}"
  - "genome.{{ hostname }}"
  - "proteomics.{{ hostname }}"
  - "singlecell.{{ hostname }}"
  - "microbiology.{{ hostname }}"
certbot_dns_provider: cloudflare
certbot_dns_credentials:
  api_token: "{{ vault_dns_cloudflare_gvl_api_token }}"
certbot_dns_provider_propagation_seconds: 60

nginx_ssl_servers:
  - galaxy
  - galaxy-gie-proxy

#gie proxy hostname
interactive_tools_server_name: "{{ hostname }}"

galaxy_db_user_password: "{{ vault_dev_db_user_password }}"

# ansible-galaxy
galaxy_dynamic_job_rules_src_dir: files/galaxy/dynamic_job_rules/dev
galaxy_dynamic_job_rules_dir: "{{ galaxy_root }}/dynamic_job_rules"
galaxy_dynamic_job_rules:
  - total_perspective_vortex/dev_default_tool.yml.j2
  - total_perspective_vortex/dev_vortex_config.yml
  - total_perspective_vortex/dev_destinations.yml.j2
  - total_perspective_vortex/dev_tools.yml.j2
  - readme.txt

galaxy_infrastructure_url: "https://dev.gvl.org.au"

galaxy_systemd_mode: gravity
galaxy_systemd_env:
  [DRMAA_LIBRARY_PATH="/usr/lib/slurm-drmaa/lib/libdrmaa.so.1"]
galaxy_gravity_state_dir: "/opt/galaxy"

galaxy_tools_indices_dir: "{{ galaxy_root }}"
galaxy_custom_indices_dir: "{{ galaxy_root }}/custom-indices"
galaxy_tmp_dir: "{{ galaxy_root }}/tmp"
galaxy_tus_upload_store: "{{ galaxy_tmp_dir }}/tus"

galaxy_job_working_directory: "{{ galaxy_tmp_dir }}/job_working_directory"

# separate galaxy location for pulsar job JWDs close to upload store
galaxy_pulsar_job_working_directory: "{{ galaxy_tmp_dir }}/pulsar_jwds"

host_galaxy_extra_dirs:
  - "{{ galaxy_pulsar_job_working_directory }}"
  - "{{ galaxy_root }}/object_store_cache"

galaxy_repo: https://github.com/usegalaxy-au/galaxy.git
galaxy_commit_id: release_25.0_au_dev

galaxy_virtualenv_command: "/usr/bin/python3.11 -m venv"

# upon upgrade to latest conda
galaxy_conda_exec: conda

galaxy_file_path: "{{ galaxy_root }}/data-3"
nginx_upload_store_base_dir: "{{ galaxy_file_path }}/upload_store"
nginx_upload_store_dir: "{{ nginx_upload_store_base_dir }}/uploads"
nginx_upload_job_files_store_dir: "{{ nginx_upload_store_base_dir }}/job_files"

galaxy_toolbox_filters_dir: /mnt/galaxy/galaxy-app/lib/galaxy/tool_util/toolbox/filters # don't ask me why. It moves.

host_galaxy_config_templates:
  - src: "{{ galaxy_config_template_src_dir }}/config/dev_object_store_conf.yml.j2"
    dest: "{{ galaxy_config_dir }}/object_store_conf.yml"
  - src: "{{ galaxy_config_template_src_dir }}/config/oidc_backends_config.xml.j2"
    dest: "{{ galaxy_config_dir}}/oidc_backends_config.xml"
  - src: "{{ galaxy_config_template_src_dir }}/config/dev_job_conf.yml.j2"
    dest: "{{ galaxy_config_dir}}/job_conf.yml"
  - src: "{{ galaxy_config_template_src_dir }}/toolbox/filters/ga_filters.py.j2"
    dest: "{{ galaxy_toolbox_filters_dir }}/ga_filters.py"
  - src: "{{ galaxy_config_template_src_dir }}/toolbox/filters/aagi_filters.py.j2"
    dest: "{{ galaxy_toolbox_filters_dir }}/aagi_filters.py"
  - src: "{{ galaxy_config_template_src_dir }}/config/object_store_templates.yml.j2"
    dest: "{{ galaxy_config_dir }}/object_store_templates.yml"
  - src: "{{ galaxy_config_template_src_dir }}/config/file_source_templates.yml.j2"
    dest: "{{ galaxy_config_dir }}/file_source_templates.yml"

host_galaxy_config_files:
  - src: "{{ galaxy_config_file_src_dir }}/config/oidc_config.xml"
    dest: "{{ galaxy_config_dir}}/oidc_config.xml"
  - src: "{{ galaxy_config_file_src_dir }}/config/local_tool_conf_dev.xml"
    dest: "{{ galaxy_config_dir }}/local_tool_conf.xml"
  - src: "{{ galaxy_config_file_src_dir }}/config/additional_datatypes_conf.xml"
    dest: "{{ galaxy_config_dir }}/additional_datatypes_conf.xml"
  - src: "{{ galaxy_config_file_src_dir }}/config/trs_servers_conf.yml"
    dest: "{{ galaxy_config_dir }}/trs_servers_conf.yml"
  - src: "{{ galaxy_config_file_src_dir }}/config/activation-email.html"
    dest: "{{ galaxy_config_dir }}/mail/activation-email.html"
  - src: "{{ galaxy_config_file_src_dir }}/config/activation-email.txt"
    dest: "{{ galaxy_config_dir }}/mail/activation-email.txt"
  - src: "{{ galaxy_config_file_src_dir }}/config/local_tool_data_table_conf.xml"
    dest: "{{ galaxy_config_dir }}/local_tool_data_table_conf.xml"
  - src: "{{ galaxy_config_file_src_dir }}/config/tool_panel_filters/proteomics.yml"
    dest: "{{ galaxy_config_dir }}/tool_panel_filters/proteomics.yml"
  - src: "{{ galaxy_config_file_src_dir }}/config/tool_panel_filters/singlecell.yml"
    dest: "{{ galaxy_config_dir }}/tool_panel_filters/singlecell.yml"
  - src: "{{ galaxy_config_file_src_dir }}/config/tool_panel_filters/microbiology.yml"
    dest: "{{ galaxy_config_dir }}/tool_panel_filters/microbiology.yml"

galaxy_config_file: /opt/galaxy/galaxy.yml

host_galaxy_config_gravity:
  process_manager: systemd
  galaxy_root: "{{ galaxy_server_dir }}"
  galaxy_user: "{{ galaxy_user.name }}"
  app_server: gunicorn
  virtualenv: "{{ galaxy_venv_dir }}"
  gunicorn:
    - bind: "0.0.0.0:8888"
      # performance options
      workers: 1
      # Other options that will be passed to gunicorn
      extra_args: '--forwarded-allow-ips="*"'
      preload: true
      environment: "{{ galaxy_process_env }}"
    - bind: "0.0.0.0:8889"
      # performance options
      workers: 1
      # Other options that will be passed to gunicorn
      extra_args: '--forwarded-allow-ips="*"'
      preload: true
      environment: "{{ galaxy_process_env }}"
  gx_it_proxy:
    enable: true
    ip: "{{ gie_proxy_ip }}"
    port: "{{ gie_proxy_port }}"
    sessions: "{{ gie_proxy_sessions_path }}"
    verbose: true
  celery:
    enable: false
    enable_beat: false
  reports:
    enable: true
    url_prefix: /reports
    bind: "unix:{{ galaxy_mutable_config_dir }}/reports.sock"
    config_file: "{{ galaxy_config_dir }}/reports.yml"
  tusd:
    enable: true
    tusd_path: /usr/local/sbin/tusd
    upload_dir: "{{ galaxy_tus_upload_store }}"

# galaxy vault key
galaxy_vault_encryption_key: "{{ vault_galaxy_vault_encryption_key_nonprod }}"

host_galaxy_config: # renamed from __galaxy_config
  gravity: "{{ host_galaxy_config_gravity }}"

  galaxy:
    activation_email: <activation-noreply@usegalaxy.org.au>
    admin_users: "{{ machine_users | selectattr('email', 'defined') | map(attribute='email') | join(',') }},{{ uwe_email }},{{ ross_email }}" # everyone is an admin on dev
    ai_api_key: "{{ vault_biocommons_galaxy_openai_api_key }}"
    ai_model: gpt-4o  # this is the default but there are many with varied prices
    amqp_internal_connection: "pyamqp://galaxy_queues:{{ vault_rabbitmq_password_galaxy_dev }}@dev-queue.gvl.org.au:5671//galaxy/galaxy_queues?ssl=1"
    brand: "Australia Dev"
    celery_conf:
      task_routes:
        galaxy.fetch_data: disabled
        galaxy.set_job_metadata: galaxy.external
    cleanup_job: never
    conda_auto_install: true  # false on production (default)
    database_connection: "postgresql://galaxy:{{ vault_dev_db_user_password }}@dev-db.gvl.org.au:5432/galaxy"
    datatypes_config_file: "{{ galaxy_server_dir }}/lib/galaxy/config/sample/datatypes_conf.xml.sample,{{ galaxy_config_dir }}/additional_datatypes_conf.xml"
    default_panel_view_by_host:
      proteomics.dev.gvl.org.au: proteomics
      singlecell.dev.gvl.org.au: singlecell
      microbiology.dev.gvl.org.au: microbiology
    email_from: <galaxy-no-reply@usegalaxy.org.au>
    enable_beta_containers_interface: true
    enable_beta_tool_formats: true  # user defined tools new as of release_25.0
    enable_celery_tasks: true
    enable_mulled_containers: true
    enable_notification_system: true
    enable_oidc: true
    file_path: "{{ galaxy_file_path }}"
    file_source_templates_config_file: "{{ galaxy_config_dir }}/file_source_templates.yml"
    id_secret: "{{ vault_dev_id_secret }}"
    interactivetools_enable: true
    interactivetools_map: "{{ gie_proxy_sessions_path }}"
    job_config_file: "{{ galaxy_config_dir }}/job_conf.yml"
    nginx_upload_job_files_path: "/_job_files"
    nginx_upload_job_files_store: "{{ nginx_upload_job_files_store_dir }}"
    nginx_upload_path: "/_upload"
    nginx_upload_store: "{{ nginx_upload_store_dir }}"
    object_store_cache_path: "{{ galaxy_root }}/object_store_cache"  # Note for production: this should be close to current object store rw folder and nginx-upload-store
    object_store_cache_size: 50  # Note for production: It might be safe to start with a small amount like 1000 (1TB) but need to be prepared to expand it (EU has 10TB)
    object_store_config_file: "{{ galaxy_config_dir }}/object_store_conf.yml"
    object_store_templates_config_file: "{{ galaxy_config_dir }}/object_store_templates.yml"
    oidc_backends_config_file: "{{ galaxy_config_dir }}/oidc_backends_config.xml"
    oidc_config_file: "{{ galaxy_config_dir }}/oidc_config.xml"
    panel_views_dir: "{{ galaxy_config_dir }}/tool_panel_filters"
    sentry_dsn: "{{ vault_sentry_dsn_dev }}"
    show_welcome_with_login: false
    smtp_server: localhost
    themes_config_file_by_host:
      genome.dev.gvl.org.au: "{{ galaxy_config_dir }}/themes/themes_genome.yml"
      proteomics.dev.gvl.org.au: "{{ galaxy_config_dir }}/themes/themes_proteomics.yml"
      singlecell.dev.gvl.org.au: "{{ galaxy_config_dir }}/themes/themes_singlecell.yml"
      dev.gvl.org.au: "{{ galaxy_config_dir }}/themes/themes_main.yml"
    tool_data_table_config_path: "{{ galaxy_config_dir }}/local_tool_data_table_conf.xml,{{ galaxy_mutable_config_dir }}/shed_tool_data_table_conf.xml,/cvmfs/data.galaxyproject.org/byhand/location/tool_data_table_conf.xml,/cvmfs/data.galaxyproject.org/managed/location/tool_data_table_conf.xml"
    tool_filters: ga_filters:hide_test_tools, aagi_filters:restrict_aagi_tools
    tool_label_filters: global_host_filters:per_host_tool_labels
    tool_section_filters: global_host_filters:per_host_tool_sections
    #TRS - workflowhub
    trs_servers_config_file: "{{ galaxy_config_dir }}/trs_servers_conf.yml"
    # TUS
    tus_upload_store: "{{ galaxy_tus_upload_store }}"
    user_activation_on: true
    watch_job_rules: true # important for total perspective vortex
    welcome_directory: plugins/welcome_page/new_user/static/topics/

galaxy_handler_count: 2 ############# europe uses 5, this could be host specific

# NFS stuff
nfs_exports:
  - "{{ galaxy_root }}  *(rw,async,no_root_squash,no_subtree_check)"

# cvmfs
cvmfs_cache_base: /mnt/var/lib/cvmfs

# vars for setting up .pgpass
pg_db_password:
  galaxy: "{{ vault_dev_db_user_password }}"
  reader: "{{ vault_dev_db_reader_password }}"
  tiaasadmin: "{{ vault_dev_db_tiaasadmin_password }}"
db_address: "dev-db.gvl.org.au"
gxadmin_ubuntu_config_dir: /home/ubuntu/.config

# host-specific settings for postfix
postfix_host_domain: "gvl.org.au"
postfix_hostname: "dev"
smtp_login: "{{ vault_smtp_login_dev }}"
smtp_password: "{{ vault_smtp_password_dev }}"

# TIaaS specific settings
tiaas_galaxy_db_host: "dev-db.gvl.org.au"
tiaas_galaxy_db_port: "5432"
tiaas_galaxy_db_user: "tiaasadmin"
tiaas_galaxy_db_pass: "{{ vault_dev_db_tiaasadmin_password }}"
tiaas_info:
  owner: "Galaxy Australia Dev"
  owner_email: help@genome.edu.au
  owner_site: https://site.usegalaxy.org.au
  domain: dev.gvl.org.au

tiaas_other_config: |
  # Cam's mailtrap account
  EMAIL_HOST = 'smtp.mailtrap.io'
  EMAIL_PORT = 2525
  EMAIL_HOST_USER = '7ac4110c7f742c'
  EMAIL_HOST_PASSWORD = '{{ tiaas_email_password }}'
  EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'
  EMAIL_TIMEOUT = 60
  TIAAS_SEND_EMAIL_TO = "help@genome.edu.au"
  TIAAS_SEND_EMAIL_FROM = "tiaas-no-reply@usegalaxy.org.au"
  TIAAS_SEND_EMAIL_TO_REQUESTER = True
  TIAAS_LATE_REQUEST_PREVENTION_DAYS = 7
  TIAAS_GDPR_AUTO_REDACT = False

# Create a cron job to disassociate training roles from groups after trainings have expired, set to `false` to disable
tiaas_disassociate_training_roles:
  hour: 9 # optional, defaults to 0
  minute: 0 # optional, defaults to 0

tiaas_show_advertising: false
tiaas_retain_contact_consent: false

# Templates to override web content:
tiaas_templates_dir: files/tiaas/html
# Static files referenced by above templates:
tiaas_extra_static_dir: files/tiaas/static

# AAF specific settings
aaf_issuer_url: "{{ vault_aaf_issuer_url_dev }}"
aaf_client_id: "{{ vault_aaf_client_id_dev }}"
aaf_client_secret: "{{ vault_aaf_client_secret_dev }}"

# remote-pulsar-cron variables
rpc_skip_cron_setup: false
rpc_db_connection_string: "postgres://reader:{{ vault_dev_db_reader_password }}@dev-db.gvl.org.au:5432/galaxy"

rpc_pulsar_machines:
  - pulsar_name: dev-pulsar
    pulsar_ip_address: "{{ hostvars['dev-pulsar']['ansible_ssh_host'] }}"
    ssh_key: /home/ubuntu/.ssh/ubuntu_maintenance_key
    delete_jwds: true
    keep_error_days: 7
    cron_hour: "07"
    cron_minute: "32"

extra_keys:
  - id: ubuntu_maintenance_key
    type: private

# Job conf limits (defined here to be available to job conf and tpv)
job_conf_limits:
  environments:
    slurm:
      tags:
        - registered_user_concurrent_jobs_20
    interactive_pulsar:
      tags:
        - registered_user_concurrent_jobs_20
    pulsar_destination:
      tags:
        - registered_user_concurrent_jobs_20
    pulsar-nci-test:
      tags:
        - registered_user_concurrent_jobs_10
    pulsar-azure-0-std:
      tags:
        - registered_user_concurrent_jobs_20
    pulsar-reservation-g2-xlarge-A:
      tags:
        - registered_user_concurrent_jobs_20
    pulsar-reservation-g2-xlarge-B:
      tags:
        - registered_user_concurrent_jobs_20
    pulsar-qld-gpu-dev:
      tags:
        - registered_user_concurrent_jobs_20
  limits:
  - type: anonymous_user_concurrent_jobs
    value: 1
  - type: destination_user_concurrent_jobs
    tag: registered_user_concurrent_jobs_20
    value: 20
  - type: destination_user_concurrent_jobs
    tag: registered_user_concurrent_jobs_40
    value: 40
  - type: destination_user_concurrent_jobs
    tag: registered_user_concurrent_jobs_10
    value: 10


# Docker
docker_users:
  - "{{ galaxy_user.name }}"
docker_daemon_options:
  data-root: /mnt/docker-data

# Singularity and docker volumes
slurm_singularity_volumes_list:
  - "$job_directory:rw"
  - "$galaxy_root:ro"
  - "$tool_directory:ro"
  - "/mnt/galaxy/data:ro"
  - "/mnt/galaxy/data-2:ro"
  - "/mnt/galaxy/data-3:ro"
  - "/mnt/galaxy/object_store_cache:ro"  # for user defined storage
  - "/mnt/galaxy/data-scratch:ro"
  - "/mnt/test_mount:ro"
  - "/mnt/galaxy/custom-indices:ro"
  - "/cvmfs/data.galaxyproject.org:ro"
  - "/mnt/galaxy/local_tools:ro"
  - "/tmp:rw"

pulsar_singularity_volumes_list:
  - "$job_directory:rw"
  - "$tool_directory:ro"
  - "/cvmfs/data.galaxyproject.org:ro"
  - "/tmp:rw"

slurm_docker_volumes_list: "{{ slurm_singularity_volumes_list }}"
pulsar_docker_volumes_list: "{{ pulsar_singularity_volumes_list }}"

# comma separated strings for the job conf
slurm_singularity_volumes: "{{ slurm_singularity_volumes_list | join(',') }}"
pulsar_singularity_volumes: "{{ pulsar_singularity_volumes_list | join(',') }}"
slurm_docker_volumes: "{{ slurm_docker_volumes_list | join(',') }}"
pulsar_docker_volumes: "{{ pulsar_docker_volumes_list | join(',') }}"

singularity_default_container_id: "/cvmfs/singularity.galaxyproject.org/all/python:3.8.3"

# multisite stuff

galaxy_subsite_base_domain: "dev.gvl.org.au"
galaxy_subsite_default_welcome: "https://site.usegalaxy.org.au"
galaxy_subsite_dir: /mnt/galaxy/subsites
#galaxy_subsite_base_css: '#masthead { background-color: #003399;}'
galaxy_subsites:
  - name: genome
    brand: Genome Lab
    iframe: "https://labs.usegalaxy.org.au/?content_root=https://github.com/galaxyproject/galaxy_codex/blob/main/communities/genome/lab/usegalaxy.org.au.yml"
    # If wallpaper is true, then files/subsites/{name}.png will be copied to
    # /static/dist/{name}.png, and can be used exactly like that in the CSS.
    wallpaper: false
    tool_sections:
      - hicexplorer
      - plots
      - assembly
      - annotation
      - phylogenetics
      - multiple_alignments
    custom_css: |
      #masthead .navbar-nav>li.active {
        background: #2c3067 !important;
      }
      #masthead {
        background: #3a3e87 !important;
      }
      #masthead a.navbar-brand::after {
          content: "Australia - Genome Lab";
      }
      #masthead .navbar-text {
          display: none;
      }
  - name: proteomics
    brand: Proteomics Lab
    iframe: "https://labs.usegalaxy.org.au/?content_root=https://github.com/galaxyproject/galaxy_codex/blob/main/communities/proteomics/lab/usegalaxy.org.au.yml"
    wallpaper: false
    tool_sections: []
    custom_css: |
      #masthead .navbar-nav>li.active {
        background: #402668 !important;
      }
      #masthead {
        background: #542a95 !important;
      }
      #masthead a.navbar-brand::after {
        content: "Australia - Proteomics Lab";
      }
      #masthead .navbar-text {
        display: none;
      }
  - name: singlecell
    brand: Single Cell Lab
    iframe: "https://labs.usegalaxy.org.au/?content_root=https://github.com/galaxyproject/galaxy_codex/blob/main/communities/spoc/lab/usegalaxy.org.au.yml"
    wallpaper: false
    tool_sections: []
    custom_css: |
      #masthead .navbar-nav>li.active {
        background: #236c6f !important;
      }
      #masthead {
        background: #209693 !important;
      }
      #masthead a.navbar-brand::after {
        content: "Australia - Single Cell Lab";
      }
      #masthead .navbar-text {
        display: none;
      }
  - name: microbiology
    brand: Microbiology Lab
    iframe: "https://labs.usegalaxy.org.au/?content_root=https://github.com/galaxyproject/galaxy_codex/blob/main/communities/microgalaxy/lab/usegalaxy.org.au.yml"
    wallpaper: false
    tool_sections: []
    custom_css: |
      #masthead .navbar-nav>li.active {
        background: #1b5b62 !important;
      }
      #masthead {
        background: #1a7b92 !important;
      }
      #masthead a.navbar-brand::after {
        content: "Australia - Microbiology Lab";
      }
      #masthead .navbar-text {
        display: none;
      }

galaxy_scratch_storage_days: 60

webhook_plugins:
  - subdomain_switcher_24.2
  - toolmsg_24.2
  - tips
  # These ones aren't in the playbook as they are included in the galaxy repo:
  - gtn
  - news

# toolmsg webhook plugin:
toolmsg_messages:
# - tool_id: to match subject.startsWith(tool_id)
#            Best to use remove version numbers and trailing slash
#            e.g. toolshed.g2.bx.psu.edu/repos/galaxyp/diann/diann
#   message: A custom HTML message to be displayed for this tool
#   class: bootstrap class [primary, info, success, warning, danger]

  - tool_id: toolshed.g2.bx.psu.edu/repos/iuc/abyss/abyss-pe
    message: >
      [TEST] Access rights to this tool have changed, please
      <a href="https://site.usegalaxy.org.au/request/access/diann"
         target="_blank"
      >
        apply for access
      </a>
      to continue using this tool.
    class: warning

walle_user_name: ubuntu
walle_user_group: ubuntu
walle_tool: interactive_tool
walle_virtualenv: "{{ galaxy_venv_dir }}"
walle_bashrc: "{{ galaxy_root }}/walle/.bashrc"
walle_malware_database_location: "{{ galaxy_root }}/walle"
walle_filesize_min: 0
walle_verbose: false
walle_kill: false
walle_slack_alerts: true
walle_slack_api_token: "{{ vault_galaxy_australia_slack_api_token }}"
walle_slack_channel_id: CJVFNFKGD
walle_cron_minute: "0"
walle_extra_env_vars:
  GALAXY_PULSAR_APP_CONF: "{{ galaxy_config_dir }}/pulsar_app.yml"
  PGHOST: "{{ db_address }}"

# auth0
auth0_client_id: "{{ vault_auth0_client_id_dev }}"
auth0_client_secret: "{{ vault_auth0_client_secret_dev }}"
auth0_oidc_endpoint: "{{ vault_auth0_oidc_endpoint_dev }}"
auth0_audience: "{{ vault_auth0_audience_dev }}"

### History mailer

# config
history_mailer_warn_days: 365
history_mailer_delete_days: 379
history_mailer_email_days_threshold: 14
history_mailer_purge_days_threshold: 6

history_mailer_galaxy_url: https://dev.gvl.org.au
history_mailer_galaxy_api_key: "{{ vault_jenkins_bot_dev_api_key }}"  # TODO: add this!

history_mailer_galaxy_keeplist_group: "History Retention Keeplist"

# history_mailer_postal_base_url: "https://mail.usegalaxy.org.au/api/v1/"
# history_mailer_postal_api_key: "{{ vault_history_mailer_postal_api_key }}"

# history_mailer_email_template_warning: "{{ history_mailer_email_template_dir }}/email_warning.html"
# history_mailer_email_template_deletion: "{{ history_mailer_email_template_dir }}/email_deletion.html"

# history_mailer_mail_from: "Galaxy Australia <no-reply@usegalaxy.org.au>"
# history_mailer_mail_replyto: "help@genome.edu.au"

# history_mailer_slack_token: "{{ vault_history_mailer_slack_token }}"
# history_mailer_slack_alert_channel: "#alerts"
# history_mailer_slack_log_channel: "#galaxy-logs"
# history_mailer_alert_mentions: "<@Catherine>"
# history_mailer_log_mentions: "<@Catherine>"

# settings for ansible role
history_mailer_user: ubuntu
history_mailer_dir: "/home/{{ history_mailer_user }}/hm_TEST"

# history_mailer_use_postal: true # Must be true for history mailer to work

history_mailer_enable_cron_jobs: false # When not enabled, cron jobs will be entered in crontab in a disabled state

history_mailer_cron_jobs:
- name: warn_and_delete
  weekday: "3"
  hour: "11"
  options:
    - production
    - warn
    - dryrun
# - name: purge_histories
#   weekday: "2"
#   hour: "12"
#   options:
#     - production
#     - purge
#     - notify

# Delete these and use vault variables
vault_history_mailer_postal_api_key: nottherealkey #
vault_history_mailer_slack_token: "xoxb"
vault_jenkins_bot_production_api_key: abcdefg # TODO: add the real one, add these to vault
vault_jenkins_bot_staging_api_key: xyz # TODO: add the real one, add these to vault
